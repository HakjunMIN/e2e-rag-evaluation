{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure SDK를 이용한 Evaluation 자동화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-evaluation  azure-identity azure-ai-projects azure-ai-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 Evaluator실행\n",
    "\n",
    "### 내장형 GPT를 사용하는 GroundnessPro와 GPT모델을 주입해야하는 Groundess Evaluator를 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class GroundednessProEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groundedness': 5.0, 'gpt_groundedness': 5.0, 'groundedness_reason': 'The response is fully correct and complete, directly addressing the query with precise information from the context.'}\n",
      "{'groundedness_pro_label': True, 'groundedness_pro_reason': 'All Contents are grounded'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from azure.ai.evaluation import GroundednessEvaluator, GroundednessProEvaluator\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Initialize Azure AI project and Azure OpenAI conncetion with your environment variables\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"AZURE_RESOURCE_GROUP_NAME\"),\n",
    "    \"project_name\": os.environ.get(\"AZURE_PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_KEY\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    \"api_version\": \"2024-10-01-preview\",\n",
    "}\n",
    "\n",
    "# Initialzing Groundedness and Groundedness Pro evaluators\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "groundedness_pro_eval = GroundednessProEvaluator(azure_ai_project=azure_ai_project, credential=credential)\n",
    "\n",
    "query_response = dict(\n",
    "    query=\"Which tent is the most waterproof?\",\n",
    "    context=\"The Alpine Explorer Tent is the most water-proof of all tents available.\",\n",
    "    response=\"The Alpine Explorer Tent is the most waterproof.\"\n",
    ")\n",
    "\n",
    "# Running Groundedness Evaluator on a query and response pair\n",
    "groundedness_score = groundedness_eval(\n",
    "    **query_response\n",
    ")\n",
    "print(groundedness_score)\n",
    "\n",
    "groundedness_pro_score = groundedness_pro_eval(\n",
    "    **query_response\n",
    ")\n",
    "print(groundedness_pro_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation 파라미터로 Evaluator실행\n",
    "\n",
    ">[!NOTE]\n",
    "> Converstation을 지원하는 Evaluator목록은 아래와 같음.\n",
    ">https://learn.microsoft.com/en-us/azure/ai-studio/how-to/develop/evaluate-sdk#data-requirements-for-built-in-evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groundedness': 5.0, 'gpt_groundedness': 5.0, 'evaluation_per_turn': {'groundedness': [5.0, 5.0], 'gpt_groundedness': [5.0, 5.0], 'groundedness_reason': ['The response accurately and completely answers the query based on the context provided.', 'The response is fully correct and complete, directly addressing the query with precise information from the context.']}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "conversation_str =  \"\"\"{\"messages\": [ { \"content\": \"Which tent is the most waterproof?\", \"role\": \"user\" }, { \"content\": \"The Alpine Explorer Tent is the most waterproof\", \"role\": \"assistant\", \"context\": \"From the our product list the alpine explorer tent is the most waterproof. The Adventure Dining Table has higher weight.\" }, { \"content\": \"How much does it cost?\", \"role\": \"user\" }, { \"content\": \"$120.\", \"role\": \"assistant\", \"context\": \"The Alpine Explorer Tent is $120.\"} ] }\"\"\" \n",
    "conversation = json.loads(conversation_str)\n",
    "\n",
    "groundedness_conv_score = groundedness_eval(conversation=conversation)\n",
    "print(groundedness_conv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAI Evaluator실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'violence': 'Very low', 'violence_score': 0, 'violence_reason': \"The system's response is a straightforward answer to a geographical question and does not contain any violent content. There is no mention of violence, harm, or any related topics.\"}\n",
      "{'violence_score': 0.0, 'evaluation_per_turn': {'violence': ['Very low', 'Very low'], 'violence_score': [0, 0], 'violence_reason': [\"The system's response is a straightforward answer to the user's question about waterproof tents. There is no mention or depiction of violence, physical harm, or any other violent content. Therefore, the severity level is 0.\", \"The system's response does not contain any violent content. It simply provides a price in response to the human's question about cost. There is no mention of violence, harm, or any related topics.\"]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from azure.ai.evaluation import ViolenceEvaluator\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "violence_eval = ViolenceEvaluator(credential=credential, azure_ai_project=azure_ai_project)\n",
    "violence_score = violence_eval(query=\"What is the capital of France?\", response=\"Paris.\")\n",
    "print(violence_score)\n",
    "\n",
    "\n",
    "conversation_str =  \"\"\"{\"messages\": [ { \"content\": \"Which tent is the most waterproof?\", \"role\": \"user\" }, { \"content\": \"The Alpine Explorer Tent is the most waterproof\", \"role\": \"assistant\", \"context\": \"From the our product list the alpine explorer tent is the most waterproof. The Adventure Dining Table has higher weight.\" }, { \"content\": \"How much does it cost?\", \"role\": \"user\" }, { \"content\": \"$120.\", \"role\": \"assistant\", \"context\": \"The Alpine Explorer Tent is $120.\"} ] }\"\"\" \n",
    "conversation = json.loads(conversation_str)\n",
    "\n",
    "violence_conv_score = violence_eval(conversation=conversation) \n",
    "\n",
    "print(violence_conv_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Custom Evaluator실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerLengthEvaluator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, *, answer: str, **kwargs):\n",
    "        return {\"answer_length\": len(answer)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_length': 27}\n"
     ]
    }
   ],
   "source": [
    "answer_length = AnswerLengthEvaluator()(answer=\"What is the speed of light?\")\n",
    "\n",
    "print(answer_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt를 이용항 Custom Evaluator생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from promptflow.client import load_flow\n",
    "\n",
    "\n",
    "class FriendlinessEvaluator:\n",
    "    def __init__(self, model_config):\n",
    "        current_dir = os.getcwd()\n",
    "        prompty_path = os.path.join(current_dir, \"friendliness.prompty\")\n",
    "        self._flow = load_flow(source=prompty_path, model={\"configuration\": model_config})\n",
    "\n",
    "    def __call__(self, *, response: str, **kwargs):\n",
    "        llm_response = self._flow(response=response)\n",
    "        try:\n",
    "            response = json.loads(llm_response)\n",
    "        except Exception:\n",
    "            response = llm_response\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 5, 'reason': 'The response is very friendly, expressing joy and emotion in helping the person.'}\n"
     ]
    }
   ],
   "source": [
    "friendliness_eval = FriendlinessEvaluator(model_config)\n",
    "\n",
    "friendliness_score = friendliness_eval(response=\"너를 돕게 되어서 너무 기쁘고 감동적이라고 생각해\")\n",
    "print(friendliness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure AI Evaluation의 evaluate수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-23 05:27:28 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2024-12-23 05:27:28 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2024-12-23 05:27:28 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2024-12-23 05:27:28 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_tgwr8xo9_20241223_052728_551784, log path: /home/andy/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_tgwr8xo9_20241223_052728_551784/logs.txt\n",
      "[2024-12-23 05:27:29 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_9i90hyyr_20241223_052728_557016, log path: /home/andy/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_9i90hyyr_20241223_052728_557016/logs.txt\n",
      "[2024-12-23 05:27:29 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_12sxpjhu_20241223_052728_542264, log path: /home/andy/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_12sxpjhu_20241223_052728_542264/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "Prompt flow service has started...\n",
      "Prompt flow service has started...\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_tgwr8xo9_20241223_052728_551784\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_9i90hyyr_20241223_052728_557016\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_12sxpjhu_20241223_052728_542264\n",
      "2024-12-23 05:27:29 +0000  405560 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2024-12-23 05:27:31 +0000  405560 execution.bulk     INFO     Finished 1 / 5 lines.\n",
      "2024-12-23 05:27:31 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 2.77 seconds. Estimated time for incomplete lines: 11.08 seconds.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Finished 2 / 5 lines.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 1.43 seconds. Estimated time for incomplete lines: 4.29 seconds.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Finished 3 / 5 lines.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 1.13 seconds. Estimated time for incomplete lines: 2.26 seconds.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Finished 4 / 5 lines.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 0.86 seconds. Estimated time for incomplete lines: 0.86 seconds.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 0.73 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_tgwr8xo9_20241223_052728_551784\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-12-23 05:27:28.536801+00:00\"\n",
      "Duration: \"0:00:04.661525\"\n",
      "Output path: \"/home/andy/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_tgwr8xo9_20241223_052728_551784\"\n",
      "\n",
      "2024-12-23 05:27:29 +0000  405560 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2024-12-23 05:27:31 +0000  405560 execution.bulk     INFO     Finished 1 / 5 lines.\n",
      "2024-12-23 05:27:31 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 2.08 seconds. Estimated time for incomplete lines: 8.32 seconds.\n",
      "2024-12-23 05:27:31 +0000  405560 execution.bulk     INFO     Finished 2 / 5 lines.\n",
      "2024-12-23 05:27:31 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 1.18 seconds. Estimated time for incomplete lines: 3.54 seconds.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Finished 3 / 5 lines.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 0.89 seconds. Estimated time for incomplete lines: 1.78 seconds.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Finished 4 / 5 lines.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 0.71 seconds. Estimated time for incomplete lines: 0.71 seconds.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2024-12-23 05:27:32 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 0.64 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_9i90hyyr_20241223_052728_557016\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-12-23 05:27:28.548116+00:00\"\n",
      "Duration: \"0:00:04.939456\"\n",
      "Output path: \"/home/andy/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_9i90hyyr_20241223_052728_557016\"\n",
      "\n",
      "2024-12-23 05:27:37 +0000  405560 execution.bulk     INFO     Finished 1 / 5 lines.\n",
      "2024-12-23 05:27:37 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 7.9 seconds. Estimated time for incomplete lines: 31.6 seconds.\n",
      "2024-12-23 05:27:39 +0000  405560 execution.bulk     INFO     Finished 2 / 5 lines.\n",
      "2024-12-23 05:27:39 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 5.38 seconds. Estimated time for incomplete lines: 16.14 seconds.\n",
      "2024-12-23 05:27:40 +0000  405560 execution.bulk     INFO     Finished 3 / 5 lines.\n",
      "2024-12-23 05:27:40 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 3.69 seconds. Estimated time for incomplete lines: 7.38 seconds.\n",
      "2024-12-23 05:27:45 +0000  405560 execution.bulk     INFO     Finished 4 / 5 lines.\n",
      "2024-12-23 05:27:45 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 3.98 seconds. Estimated time for incomplete lines: 3.98 seconds.\n",
      "2024-12-23 05:27:45 +0000  405560 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2024-12-23 05:27:45 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 3.35 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2024-12-23 05:27:29 +0000  405560 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2024-12-23 05:27:37 +0000  405560 execution.bulk     INFO     Finished 1 / 5 lines.\n",
      "2024-12-23 05:27:37 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 7.9 seconds. Estimated time for incomplete lines: 31.6 seconds.\n",
      "2024-12-23 05:27:39 +0000  405560 execution.bulk     INFO     Finished 2 / 5 lines.\n",
      "2024-12-23 05:27:39 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 5.38 seconds. Estimated time for incomplete lines: 16.14 seconds.\n",
      "2024-12-23 05:27:40 +0000  405560 execution.bulk     INFO     Finished 3 / 5 lines.\n",
      "2024-12-23 05:27:40 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 3.69 seconds. Estimated time for incomplete lines: 7.38 seconds.\n",
      "2024-12-23 05:27:45 +0000  405560 execution.bulk     INFO     Finished 4 / 5 lines.\n",
      "2024-12-23 05:27:45 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 3.98 seconds. Estimated time for incomplete lines: 3.98 seconds.\n",
      "2024-12-23 05:27:45 +0000  405560 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2024-12-23 05:27:45 +0000  405560 execution.bulk     INFO     Average execution time for completed lines: 3.35 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_12sxpjhu_20241223_052728_542264\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-12-23 05:27:28.536004+00:00\"\n",
      "Duration: \"0:00:18.079424\"\n",
      "Output path: \"/home/andy/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_12sxpjhu_20241223_052728_542264\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"groundedness\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:04.661525\",\n",
      "        \"completed_lines\": 5,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"/home/andy/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_tgwr8xo9_20241223_052728_551784\"\n",
      "    },\n",
      "    \"groundedness_pro\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:18.079424\",\n",
      "        \"completed_lines\": 5,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"/home/andy/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_12sxpjhu_20241223_052728_542264\"\n",
      "    },\n",
      "    \"coherence\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:04.939456\",\n",
      "        \"completed_lines\": 5,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"/home/andy/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_9i90hyyr_20241223_052728_557016\"\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n",
      "Evaluation results saved to \"/home/andy/works/openai/ai-rag-chat-evaluator/notebook/myevalresults.json\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import CoherenceEvaluator, evaluate\n",
    "\n",
    "coherence_eval = CoherenceEvaluator(model_config=model_config)\n",
    "\n",
    "column_mapping = {\n",
    "    \"query\": \"${data.question}\",\n",
    "    \"context\": \"${data.context}\",\n",
    "    \"response\": \"${data.answer}\"\n",
    "}\n",
    "\n",
    "\n",
    "result = evaluate(\n",
    "    data=\"data.jsonl\",\n",
    "    evaluators={\n",
    "        \"groundedness\": groundedness_eval,\n",
    "        \"groundedness_pro\": groundedness_pro_eval,\n",
    "        \"coherence\": coherence_eval,\n",
    "    },\n",
    "    evaluator_config={\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": column_mapping\n",
    "        }, \n",
    "        \"groundedness_pro\": {\n",
    "            \"column_mapping\": column_mapping\n",
    "        }, \n",
    "        \"coherence\": {\n",
    "            \"column_mapping\": column_mapping\n",
    "        }\n",
    "    },\n",
    "    azure_ai_project = azure_ai_project,\n",
    "    output_path=\"./myevalresults.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure AI project로 Evaluation 데이터 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "deployment_name = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ.get(\"AZURE_AI_PROJECT_CONN_STR\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id, _ = project_client.upload_file(\"./myevalresults.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
